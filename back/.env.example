# LLM Provider Configuration
# Supported providers: openai, grok, gemini, groq
# Best models for PDF extraction:
#   - OpenAI: gpt-4o (excellent for structured JSON)
#   - Gemini: gemini-1.5-pro (large context, native JSON)
#   - Groq: llama-3.1-70b-versatile (fast inference, good extraction)
#   - Grok: grok-beta (experimental)
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o

# Grok (xAI) Configuration
GROK_API_KEY=your_grok_api_key_here
GROK_MODEL=grok-beta

# Gemini (Google) Configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-pro

# Groq Configuration (Fast Inference)
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-70b-versatile

# Database
DATABASE_URL=postgresql+psycopg://postgres:postgres@db:5432/hackathon
